{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "\n",
    "from local_tabnet import TabNet as LocalTabNet\n",
    "from google_tabnet import TabNet as GoogleTabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 14:39:25.724400: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-02-19 14:39:25.724479: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (al3615): /proc/driver/nvidia/version does not exist\n",
      "2024-02-19 14:39:25.725209: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "FEAT_DIM = 5\n",
    "ATTN_DIM = 2\n",
    "OUTPUT_DIM = 1\n",
    "OUTPUT_ACTIVATION = None\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "model = LocalTabNet(\n",
    "    FEAT_DIM,\n",
    "    ATTN_DIM,\n",
    "    OUTPUT_DIM,\n",
    "    OUTPUT_ACTIVATION,\n",
    "    sparsity=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 14:39:31.279602: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.1268824]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_in = tf.ones((1, FEAT_DIM), dtype=\"float\")\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\", \"mse\"]\n",
    ")\n",
    "model.predict(dummy_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tab_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "shared_feature_layer (Shared multiple                  152       \n",
      "_________________________________________________________________\n",
      "feat_0 (FeatureTransformer)  multiple                  296       \n",
      "_________________________________________________________________\n",
      "feat_1 (FeatureTransformer)  multiple                  296       \n",
      "_________________________________________________________________\n",
      "feat_2 (FeatureTransformer)  multiple                  296       \n",
      "_________________________________________________________________\n",
      "feat_3 (FeatureTransformer)  multiple                  296       \n",
      "_________________________________________________________________\n",
      "feat_4 (FeatureTransformer)  multiple                  296       \n",
      "_________________________________________________________________\n",
      "feat_5 (FeatureTransformer)  multiple                  296       \n",
      "_________________________________________________________________\n",
      "attn_1 (AttentiveTransformer multiple                  35        \n",
      "_________________________________________________________________\n",
      "attn_2 (AttentiveTransformer multiple                  35        \n",
      "_________________________________________________________________\n",
      "attn_3 (AttentiveTransformer multiple                  35        \n",
      "_________________________________________________________________\n",
      "attn_4 (AttentiveTransformer multiple                  35        \n",
      "_________________________________________________________________\n",
      "attn_5 (AttentiveTransformer multiple                  35        \n",
      "_________________________________________________________________\n",
      "norm_in (BatchNormalization) multiple                  20        \n",
      "_________________________________________________________________\n",
      "output (Dense)               multiple                  3         \n",
      "=================================================================\n",
      "Total params: 1,216\n",
      "Trainable params: 930\n",
      "Non-trainable params: 286\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mask_entropy']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a step of fit and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 11s 11s/step - loss: 2.6094 - mae: 1.0000 - mse: 1.0000 - mask_entropy: 1.6094 - val_loss: 2.9104 - val_mae: 1.1533 - val_mse: 1.3302 - val_mask_entropy: 1.5803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['loss', 'mae', 'mse', 'mask_entropy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        tf.ones((1, FEAT_DIM), dtype=\"float\"),\n",
    "        tf.ones((1, OUTPUT_DIM), dtype=\"float\")\n",
    "    )\n",
    ").batch(1)\n",
    "model.fit(\n",
    "    dummy_dataset,\n",
    "    epochs=1,\n",
    "    batch_size=1,\n",
    "    verbose=1,\n",
    "    validation_data=dummy_dataset,\n",
    "    validation_freq=1,\n",
    ")\n",
    "\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 25)                150       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 826\n",
      "Trainable params: 826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "small_model = Sequential([\n",
    "    Dense(25, input_shape=(FEAT_DIM,), activation=\"relu\"),\n",
    "    Dense(25, activation=\"relu\"),\n",
    "    Dense(1, activation=\"relu\")\n",
    "])\n",
    "small_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\", \"mse\"]\n",
    ")\n",
    "small_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 429ms/step - loss: 1.0000 - mae: 1.0000 - mse: 1.0000 - val_loss: 1.0000 - val_mae: 1.0000 - val_mse: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f19db791220>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model.fit(\n",
    "    dummy_dataset,\n",
    "    epochs=1,\n",
    "    batch_size=1,\n",
    "    verbose=1,\n",
    "    validation_data=dummy_dataset,\n",
    "    validation_freq=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.641025641025642"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11/429e-3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to google implementation\n",
    "Currently not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "tf.random.set_seed(1)\n",
    "model = GoogleTabNet(\n",
    "    columns=[tf.feature_column.numeric_column(str(ci)) for ci in range(FEAT_DIM)],\n",
    "    num_features=FEAT_DIM,\n",
    "    feature_dim=ATTN_DIM,\n",
    "    output_dim=ATTN_DIM,\n",
    "    num_decision_steps=5,\n",
    "    relaxation_factor=1.5,\n",
    "    batch_momentum=0.95,\n",
    "    virtual_batch_size=None,\n",
    "    num_classes=OUTPUT_DIM\n",
    ")\n",
    "decision, total_entropy = model.encoder(dummy_in, reuse=False, is_training=False)\n",
    "out = model.regress(decision, reuse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabnet",
   "language": "python",
   "name": "tabnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
